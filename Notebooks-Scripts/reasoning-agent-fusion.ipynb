{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12570765,"sourceType":"datasetVersion","datasetId":7938532},{"sourceId":12570789,"sourceType":"datasetVersion","datasetId":7938542},{"sourceId":12571222,"sourceType":"datasetVersion","datasetId":7938842},{"sourceId":12573475,"sourceType":"datasetVersion","datasetId":7940493}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e21e53f5-cd97-4795-8759-608d8e0000bf","cell_type":"code","source":"import pandas as pd\nimport re\nfrom tqdm import tqdm\nimport ftfy\nimport html\nimport os, zipfile\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.optim import AdamW\nfrom sklearn.metrics import classification_report\nfrom torchvision.models import resnet50\nimport torch.nn as nn\nfrom torchvision import transforms,models\nfrom PIL import Image\nfrom torch.utils.data import WeightedRandomSampler\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-25T10:12:56.167620Z","iopub.execute_input":"2025-07-25T10:12:56.168172Z","iopub.status.idle":"2025-07-25T10:12:56.172959Z","shell.execute_reply.started":"2025-07-25T10:12:56.168148Z","shell.execute_reply":"2025-07-25T10:12:56.172357Z"}},"outputs":[],"execution_count":12},{"id":"2911ff66-fc84-4eab-9cba-a0f4607e3045","cell_type":"code","source":"CSV_PATH = \"/kaggle/input/cleaned-fusion-with-text/cleaned_fusion_with_text.csv\"\nIMAGE_DIR = \"/kaggle/input/data-image/data_image\"\nTEXT_MODEL_PATH = \"/kaggle/input/text-agent-bertweet/text_agent_bertweet.pth\"\nVISION_MODEL_PATH = \"/kaggle/input/vision-agent-resnet50/vision_agent_resnet50.pth\"\nFUSION_MODEL_PATH = \"/kaggle/working/reasoning_agent_fusion.pth\"\nREPORT_PATH = \"/kaggle/working/reasoning_agent_classification_report.txt\"\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nBATCH_SIZE = 16\nEPOCHS = 5\nNUM_CLASSES = 6\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-25T09:49:18.692905Z","iopub.execute_input":"2025-07-25T09:49:18.693357Z","iopub.status.idle":"2025-07-25T09:49:18.756856Z","shell.execute_reply.started":"2025-07-25T09:49:18.693335Z","shell.execute_reply":"2025-07-25T09:49:18.756208Z"}},"outputs":[],"execution_count":5},{"id":"c97c4980-01ba-4407-9eb8-0f4b5c6b3a49","cell_type":"code","source":"vision_model = models.resnet50(weights=None)  # Don't load pretrained weights\nvision_model.fc = nn.Linear(vision_model.fc.in_features, NUM_CLASSES)  # 6 classes as in your training\nvision_model.load_state_dict(torch.load(VISION_MODEL_PATH, map_location=DEVICE, weights_only=False))\nvision_model.to(DEVICE)\nvision_model.eval()\n\n# Create a feature extractor from the vision model (remove the final classification layer)\nclass VisionFeatureExtractor(nn.Module):\n    def __init__(self, base_model):\n        super().__init__()\n        # Remove the final fc layer to get features\n        self.features = nn.Sequential(*list(base_model.children())[:-1])\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        \n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        return x\n\nvision_agent = VisionFeatureExtractor(vision_model)\nvision_agent.to(DEVICE)\nvision_agent.eval()\n\n# Load text model\ntext_agent = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=6)\ncheckpoint = torch.load(TEXT_MODEL_PATH, map_location=DEVICE, weights_only=False)\ntext_agent.load_state_dict(checkpoint[\"model_state_dict\"])\ntext_agent.to(DEVICE)\ntext_agent.eval()\n\ntokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n\nimage_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nclass FusionDataset(Dataset):\n    def __init__(self, df, label_encoder=None):\n        self.df = df.copy()\n        \n        # Create or use provided label encoder\n        if label_encoder is None:\n            from sklearn.preprocessing import LabelEncoder\n            self.label_encoder = LabelEncoder()\n            self.df['label'] = self.label_encoder.fit_transform(self.df['disaster_type'])\n        else:\n            self.label_encoder = label_encoder\n            self.df['label'] = self.label_encoder.transform(self.df['disaster_type'])\n        \n        print(f\"Dataset created with {len(self.df)} samples\")\n        print(f\"Sample labels: {self.df['label'].head().tolist()}\")\n        print(f\"Sample disaster_types: {self.df['disaster_type'].head().tolist()}\")\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(IMAGE_DIR, row[\"image_name\"])\n        tweet = row[\"tweet_text_clean\"]\n        # Use the numeric label (guaranteed to exist now)\n        label = row[\"label\"]\n        \n        # Debug print to check label type (only for first few items)\n        if idx < 3:\n            print(f\"Sample {idx} - Label: {label} (type: {type(label)}), Disaster type: {row['disaster_type']}\")\n        \n        # Load and process image\n        image = Image.open(img_path).convert('RGB')\n        image = image_transform(image).unsqueeze(0).to(DEVICE)\n        \n        # Extract vision features (now 2048-dimensional from ResNet50 before final fc)\n        with torch.no_grad():\n            vision_feat = vision_agent(image).squeeze(0)\n        \n        # Process text\n        encoded = tokenizer(tweet, return_tensors=\"pt\", padding=\"max_length\", \n                          truncation=True, max_length=128)\n        input_ids = encoded['input_ids'].to(DEVICE)\n        attention_mask = encoded['attention_mask'].to(DEVICE)\n        \n        # Extract text features (get hidden states from the model)\n        with torch.no_grad():\n            outputs = text_agent(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n            # Use the [CLS] token representation from the last hidden layer\n            text_feat = outputs.hidden_states[-1][:, 0, :].squeeze(0)\n        \n        # Ensure label is numeric\n        if isinstance(label, str):\n            label = self.label_encoder.transform([label])[0]\n        \n        return vision_feat.cpu(), text_feat.cpu(), torch.tensor(int(label), dtype=torch.long)\n\nclass ReasoningAgent(nn.Module):\n    def __init__(self, vision_dim=2048, text_dim=768, hidden_dim=512, num_classes=6):\n        super().__init__()\n        self.fc1 = nn.Linear(vision_dim + text_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.3)\n        self.fc2 = nn.Linear(hidden_dim, num_classes)\n    \n    def forward(self, vision_feat, text_feat):\n        x = torch.cat((vision_feat, text_feat), dim=1)\n        x = self.dropout(self.relu(self.fc1(x)))\n        return self.fc2(x)\n\ndef train_model():\n    df = pd.read_csv(CSV_PATH)\n    \n    # Create and fit the label encoder\n    from sklearn.preprocessing import LabelEncoder\n    from torch.utils.data import WeightedRandomSampler\n    import numpy as np\n    \n    label_encoder = LabelEncoder()\n    \n    print(\"Original disaster types:\", df['disaster_type'].unique())\n    \n    # Fit the label encoder first\n    label_encoder.fit(df['disaster_type'])\n    \n    print(\"Classes:\", label_encoder.classes_)\n    print(\"Label mapping:\", dict(zip(label_encoder.classes_, range(len(label_encoder.classes_)))))\n    \n    # Create the dataset with the fitted label encoder\n    dataset = FusionDataset(df, label_encoder)\n    \n    # Calculate class weights for balanced sampling\n    labels = dataset.df['label'].values\n    class_counts = np.bincount(labels)\n    print(\"Class distribution:\", dict(zip(range(len(class_counts)), class_counts)))\n    \n    # Calculate weights (inverse of class frequency)\n    class_weights = 1.0 / class_counts\n    sample_weights = class_weights[labels]\n    \n    print(\"Class weights:\", class_weights)\n    print(\"Using WeightedRandomSampler for balanced training\")\n    \n    # Create sampler for balanced sampling\n    sampler = WeightedRandomSampler(\n        weights=sample_weights,\n        num_samples=len(sample_weights),\n        replacement=True\n    )\n    \n    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=sampler)\n    \n    model = ReasoningAgent().to(DEVICE)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    \n    model.train()\n    for epoch in range(EPOCHS):\n        total_loss = 0\n        for vision_feat, text_feat, labels in dataloader:\n            vision_feat = vision_feat.to(DEVICE)\n            text_feat = text_feat.to(DEVICE)\n            labels = labels.to(DEVICE)\n            \n            outputs = model(vision_feat, text_feat)\n            loss = criterion(outputs, labels)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n        \n        print(f\"Epoch {epoch+1}: Loss = {total_loss/len(dataloader):.4f}\")\n    \n    return model, dataset\n\ndef evaluate_model(model, dataset):\n    model.eval()\n    y_true, y_pred = [], []\n    \n    with torch.no_grad():\n        for vision_feat, text_feat, labels in DataLoader(dataset, batch_size=1):\n            vision_feat = vision_feat.to(DEVICE)\n            text_feat = text_feat.to(DEVICE)\n            \n            outputs = model(vision_feat, text_feat)\n            preds = torch.argmax(outputs, dim=1).cpu().item()\n            \n            y_pred.append(preds)\n            y_true.append(labels.item())\n    \n    report = classification_report(y_true, y_pred, digits=4)\n    print(report)\n    \n    with open(REPORT_PATH, \"w\") as f:\n        f.write(report)\n\n# Main execution\nmodel, dataset = train_model()\nevaluate_model(model, dataset)\ntorch.save(model.state_dict(), FUSION_MODEL_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-25T10:13:05.118778Z","iopub.execute_input":"2025-07-25T10:13:05.119069Z","iopub.status.idle":"2025-07-25T10:34:44.743267Z","shell.execute_reply.started":"2025-07-25T10:13:05.119049Z","shell.execute_reply":"2025-07-25T10:34:44.742414Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Original disaster types: ['hurricane_maria' 'california_wildfires' 'hurricane_harvey'\n 'hurricane_irma' 'srilanka_floods' 'iraq_iran_earthquake']\nClasses: ['california_wildfires' 'hurricane_harvey' 'hurricane_irma'\n 'hurricane_maria' 'iraq_iran_earthquake' 'srilanka_floods']\nLabel mapping: {'california_wildfires': 0, 'hurricane_harvey': 1, 'hurricane_irma': 2, 'hurricane_maria': 3, 'iraq_iran_earthquake': 4, 'srilanka_floods': 5}\nDataset created with 8534 samples\nSample labels: [3, 0, 3, 1, 2]\nSample disaster_types: ['hurricane_maria', 'california_wildfires', 'hurricane_maria', 'hurricane_harvey', 'hurricane_irma']\nClass distribution: {0: 942, 1: 2095, 2: 1944, 3: 2711, 4: 550, 5: 292}\nClass weights: [0.00106157 0.00047733 0.0005144  0.00036887 0.00181818 0.00342466]\nUsing WeightedRandomSampler for balanced training\nSample 2 - Label: 3 (type: <class 'numpy.int64'>), Disaster type: hurricane_maria\nSample 1 - Label: 0 (type: <class 'numpy.int64'>), Disaster type: california_wildfires\nSample 2 - Label: 3 (type: <class 'numpy.int64'>), Disaster type: hurricane_maria\nEpoch 1: Loss = 0.1455\nEpoch 2: Loss = 0.0157\nSample 1 - Label: 0 (type: <class 'numpy.int64'>), Disaster type: california_wildfires\nSample 1 - Label: 0 (type: <class 'numpy.int64'>), Disaster type: california_wildfires\nSample 1 - Label: 0 (type: <class 'numpy.int64'>), Disaster type: california_wildfires\nSample 1 - Label: 0 (type: <class 'numpy.int64'>), Disaster type: california_wildfires\nEpoch 3: Loss = 0.0148\nSample 1 - Label: 0 (type: <class 'numpy.int64'>), Disaster type: california_wildfires\nSample 2 - Label: 3 (type: <class 'numpy.int64'>), Disaster type: hurricane_maria\nEpoch 4: Loss = 0.0188\nSample 1 - Label: 0 (type: <class 'numpy.int64'>), Disaster type: california_wildfires\nSample 1 - Label: 0 (type: <class 'numpy.int64'>), Disaster type: california_wildfires\nSample 0 - Label: 3 (type: <class 'numpy.int64'>), Disaster type: hurricane_maria\nEpoch 5: Loss = 0.0119\nSample 0 - Label: 3 (type: <class 'numpy.int64'>), Disaster type: hurricane_maria\nSample 1 - Label: 0 (type: <class 'numpy.int64'>), Disaster type: california_wildfires\nSample 2 - Label: 3 (type: <class 'numpy.int64'>), Disaster type: hurricane_maria\n              precision    recall  f1-score   support\n\n           0     1.0000    1.0000    1.0000       942\n           1     0.9858    0.9962    0.9910      2095\n           2     0.9974    0.9779    0.9875      1944\n           3     0.9938    0.9993    0.9965      2711\n           4     1.0000    1.0000    1.0000       550\n           5     0.9966    1.0000    0.9983       292\n\n    accuracy                         0.9938      8534\n   macro avg     0.9956    0.9956    0.9956      8534\nweighted avg     0.9938    0.9938    0.9938      8534\n\n","output_type":"stream"}],"execution_count":13},{"id":"16c82ffc-1ef6-42b1-a666-c3af240252ff","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}